{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n",
      "1.14.5\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from mxnet import nd, autograd, gluon\n",
    "import multiprocessing\n",
    "\n",
    "print(mx.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.random.seed(1)\n",
    "ctx = mx.gpu(0)\n",
    "batch_size = 64\n",
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "num_fc = 512\n",
    "max_batches = 300\n",
    "max_batches_infer = 1000\n",
    "# We delay concatening arrays and calculating accuracy until after the inference\n",
    "# to make sure benchmarking is consistent\n",
    "acc = lambda res_list : np.mean([np.mean(np.argmax(x.softmax().asnumpy(), axis=1) == y.asnumpy()) for x, y in res_list])\n",
    "\n",
    "def transformer(data, label):\n",
    "        data = mx.image.imresize(data, 224, 224)\n",
    "        data = mx.nd.transpose(data, (2,0,1))\n",
    "        return data, label\n",
    "\n",
    "def train_model(dtype, name, **sgd_kwargs):\n",
    "    net = gluon.nn.HybridSequential()\n",
    "    with net.name_scope():\n",
    "        #  First convolutional layer\n",
    "        net.add(gluon.nn.Conv2D(channels=96, kernel_size=11, strides=(4,4), activation='relu'))\n",
    "        net.add(gluon.nn.MaxPool2D(pool_size=3, strides=2))\n",
    "        #  Second convolutional layer\n",
    "        net.add(gluon.nn.Conv2D(channels=192, kernel_size=5, activation='relu'))\n",
    "        net.add(gluon.nn.MaxPool2D(pool_size=3, strides=(2,2)))\n",
    "        # Third convolutional layer\n",
    "        net.add(gluon.nn.Conv2D(channels=384, kernel_size=3, activation='relu'))\n",
    "        # Fourth convolutional layer\n",
    "        net.add(gluon.nn.Conv2D(channels=384, kernel_size=3, activation='relu'))\n",
    "        # Fifth convolutional layer\n",
    "        net.add(gluon.nn.Conv2D(channels=256, kernel_size=3, activation='relu'))\n",
    "        net.add(gluon.nn.MaxPool2D(pool_size=3, strides=2))\n",
    "        # Flatten and apply fullly connected layers\n",
    "        net.add(gluon.nn.Flatten())\n",
    "        net.add(gluon.nn.Dense(4096, activation=\"relu\"))\n",
    "        net.add(gluon.nn.Dense(4096, activation=\"relu\"))\n",
    "        net.add(gluon.nn.Dense(10))\n",
    "    ### CAST NET TO CORRECT DTYPE ###\n",
    "    net.cast(dtype)\n",
    "    ###\n",
    "    net.hybridize()\n",
    "    # Parameter initialization\n",
    "    net.collect_params().initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': .001, **sgd_kwargs})\n",
    "    softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "    data_iter = gluon.data.DataLoader(\n",
    "        gluon.data.vision.CIFAR10('./data', train=True, transform=transformer),\n",
    "        batch_size=batch_size, shuffle=True, last_batch='discard')\n",
    "    for i, batch in enumerate(data_iter):\n",
    "        if i >= max_batches:\n",
    "            print(\"Reached {} batches. Saving model.\".format(max_batches))\n",
    "            break\n",
    "        d, l = batch\n",
    "        data = d.as_in_context(ctx).astype(dtype, copy=False)\n",
    "        label = l.as_in_context(ctx)\n",
    "        with autograd.record():\n",
    "            output = net(data)\n",
    "            loss = softmax_cross_entropy(output, label)\n",
    "        loss.backward()\n",
    "        trainer.step(data.shape[0])\n",
    "        \n",
    "    net.export(name)\n",
    "    return net\n",
    "\n",
    "def get_model(name, ctx):\n",
    "    return mx.gluon.block.SymbolBlock.imports(name+'-symbol.json', ['data'], name+'-0000.params', ctx=ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With normal Gluon block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached 300 batches. Saving model.\n"
     ]
    }
   ],
   "source": [
    "def fp32_transformer(data, label):\n",
    "    data = mx.image.imresize(data, 224, 224)\n",
    "    data = mx.nd.transpose(data, (2,0,1))\n",
    "    data = data.astype(np.float32, copy=False)\n",
    "    return data, label\n",
    "\n",
    "train_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.CIFAR10('./data', train=True, transform=fp32_transformer),\n",
    "    batch_size=32, shuffle=True, last_batch='discard')\n",
    "net = train_model(np.float32, 'fp32')\n",
    "# net = get_model('fp32')\n",
    "\n",
    "res_list = []\n",
    "import time\n",
    "start = time.time()\n",
    "for i, batch in enumerate(train_data):\n",
    "    if i >= max_batches_infer:\n",
    "        print(\"Reached {} batches.\".format(max_batches_infer))\n",
    "        break\n",
    "    d, l = batch\n",
    "    data = d.as_in_context(ctx)\n",
    "    res = net(data)\n",
    "    res_list.append((res, l))\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc(res_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With fp16 Gluon block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fp16_transformer(data, label):\n",
    "    data = mx.image.imresize(data, 224, 224)\n",
    "    data = mx.nd.transpose(data, (2,0,1))\n",
    "    data = data.astype(np.float16, copy=False)\n",
    "    return data, label\n",
    "\n",
    "train_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.CIFAR10('./data', train=True, transform=fp16_transformer),\n",
    "    batch_size=32, shuffle=True, last_batch='discard')\n",
    "\n",
    "net = train_model(np.float16, 'fp16', multi_precision=True)\n",
    "# net = get_model('fp16')\n",
    "\n",
    "res_list = []\n",
    "import time\n",
    "start = time.time()\n",
    "for i, batch in enumerate(train_data):\n",
    "    if i >= max_batches_infer:\n",
    "        print(\"Reached {} batches.\".format(max_batches_infer))\n",
    "        break\n",
    "    d, l = batch\n",
    "    data = d.as_in_context(ctx)\n",
    "    res = net(data)\n",
    "    res_list.append((res, l))\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = lambda res_list : np.mean([np.mean(np.argmax(x.softmax().asnumpy(), axis=1) == y.asnumpy()) for x, y in res_list])\n",
    "print(acc(res_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.collect_params()[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block2symbol(block):\n",
    "    data = mx.sym.Variable('data')\n",
    "    sym = block(data)\n",
    "    params = block.collect_params()\n",
    "    print(params)\n",
    "    arg_params = {k : mx.nd.array(v.data().asnumpy()) for k, v in params.items()}\n",
    "    aux_params = {k : mx.nd.array(v.data().asnumpy()) for k, v in params.items()}\n",
    "    return sym, arg_params, aux_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hybridsequential1_ (\n",
      "  Parameter hybridsequential1_conv0_weight (shape=(96, 3, 11, 11), dtype=<class 'numpy.float16'>)\n",
      "  Parameter hybridsequential1_conv0_bias (shape=(96,), dtype=<class 'numpy.float16'>)\n",
      "  Parameter hybridsequential1_conv1_weight (shape=(192, 96, 5, 5), dtype=<class 'numpy.float16'>)\n",
      "  Parameter hybridsequential1_conv1_bias (shape=(192,), dtype=<class 'numpy.float16'>)\n",
      "  Parameter hybridsequential1_conv2_weight (shape=(384, 192, 3, 3), dtype=<class 'numpy.float16'>)\n",
      "  Parameter hybridsequential1_conv2_bias (shape=(384,), dtype=<class 'numpy.float16'>)\n",
      "  Parameter hybridsequential1_conv3_weight (shape=(384, 384, 3, 3), dtype=<class 'numpy.float16'>)\n",
      "  Parameter hybridsequential1_conv3_bias (shape=(384,), dtype=<class 'numpy.float16'>)\n",
      "  Parameter hybridsequential1_conv4_weight (shape=(256, 384, 3, 3), dtype=<class 'numpy.float16'>)\n",
      "  Parameter hybridsequential1_conv4_bias (shape=(256,), dtype=<class 'numpy.float16'>)\n",
      "  Parameter hybridsequential1_dense0_weight (shape=(4096, 256), dtype=<class 'numpy.float16'>)\n",
      "  Parameter hybridsequential1_dense0_bias (shape=(4096,), dtype=<class 'numpy.float16'>)\n",
      "  Parameter hybridsequential1_dense1_weight (shape=(4096, 4096), dtype=<class 'numpy.float16'>)\n",
      "  Parameter hybridsequential1_dense1_bias (shape=(4096,), dtype=<class 'numpy.float16'>)\n",
      "  Parameter hybridsequential1_dense2_weight (shape=(10, 4096), dtype=<class 'numpy.float16'>)\n",
      "  Parameter hybridsequential1_dense2_bias (shape=(10,), dtype=<class 'numpy.float16'>)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "sym, arg, aux = block2symbol(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.cast(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype of hybridsequential1_conv0_weight : <class 'numpy.float32'>\n",
      "dtype of hybridsequential1_conv0_bias : <class 'numpy.float32'>\n",
      "dtype of hybridsequential1_conv1_weight : <class 'numpy.float32'>\n",
      "dtype of hybridsequential1_conv1_bias : <class 'numpy.float32'>\n",
      "dtype of hybridsequential1_conv2_weight : <class 'numpy.float32'>\n",
      "dtype of hybridsequential1_conv2_bias : <class 'numpy.float32'>\n",
      "dtype of hybridsequential1_conv3_weight : <class 'numpy.float32'>\n",
      "dtype of hybridsequential1_conv3_bias : <class 'numpy.float32'>\n",
      "dtype of hybridsequential1_conv4_weight : <class 'numpy.float32'>\n",
      "dtype of hybridsequential1_conv4_bias : <class 'numpy.float32'>\n",
      "dtype of hybridsequential1_dense0_weight : <class 'numpy.float32'>\n",
      "dtype of hybridsequential1_dense0_bias : <class 'numpy.float32'>\n",
      "dtype of hybridsequential1_dense1_weight : <class 'numpy.float32'>\n",
      "dtype of hybridsequential1_dense1_bias : <class 'numpy.float32'>\n",
      "dtype of hybridsequential1_dense2_weight : <class 'numpy.float32'>\n",
      "dtype of hybridsequential1_dense2_bias : <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "for k in arg:\n",
    "    print(\"dtype of {} : {}\".format(k, arg[k].dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = get_model('fp32', mx.gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.collect_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (User)",
   "language": "python",
   "name": "user_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
