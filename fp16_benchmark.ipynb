{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n",
      "1.14.5\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from mxnet import nd, autograd, gluon\n",
    "import multiprocessing\n",
    "\n",
    "print(mx.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.random.seed(1)\n",
    "ctx = mx.gpu(0)\n",
    "batch_size = 64\n",
    "max_batches = 300\n",
    "max_batches_infer = -1 # for whole batch\n",
    "# We delay concatening arrays and calculating accuracy until after the inference\n",
    "# to make sure benchmarking is consistent\n",
    "acc = lambda res_list : np.mean([np.mean(np.argmax(x.softmax().asnumpy(), axis=1) == y.asnumpy()) for x, y in res_list])\n",
    "\n",
    "def transformer(data, label):\n",
    "        data = mx.image.imresize(data, 224, 224)\n",
    "        data = mx.nd.transpose(data, (2,0,1))\n",
    "        return data, label\n",
    "\n",
    "def train_model(dtype, name, **sgd_kwargs):\n",
    "    net = gluon.nn.HybridSequential()\n",
    "    with net.name_scope():\n",
    "        #  First convolutional layer\n",
    "        net.add(gluon.nn.Conv2D(channels=96, kernel_size=11, strides=(4,4), activation='relu'))\n",
    "        net.add(gluon.nn.MaxPool2D(pool_size=3, strides=2))\n",
    "        #  Second convolutional layer\n",
    "        net.add(gluon.nn.Conv2D(channels=192, kernel_size=5, activation='relu'))\n",
    "        net.add(gluon.nn.MaxPool2D(pool_size=3, strides=(2,2)))\n",
    "        # Third convolutional layer\n",
    "        net.add(gluon.nn.Conv2D(channels=384, kernel_size=3, activation='relu'))\n",
    "        # Fourth convolutional layer\n",
    "        net.add(gluon.nn.Conv2D(channels=384, kernel_size=3, activation='relu'))\n",
    "        # Fifth convolutional layer\n",
    "        net.add(gluon.nn.Conv2D(channels=256, kernel_size=3, activation='relu'))\n",
    "        net.add(gluon.nn.MaxPool2D(pool_size=3, strides=2))\n",
    "        # Flatten and apply fullly connected layers\n",
    "        net.add(gluon.nn.Flatten())\n",
    "        net.add(gluon.nn.Dense(4096, activation=\"relu\"))\n",
    "        net.add(gluon.nn.Dense(4096, activation=\"relu\"))\n",
    "        net.add(gluon.nn.Dense(10))\n",
    "    ### CAST NET TO CORRECT DTYPE ###\n",
    "    net.cast(dtype)\n",
    "    ###\n",
    "    net.hybridize()\n",
    "    # Parameter initialization\n",
    "    net.collect_params().initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': .001, **sgd_kwargs})\n",
    "    softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "    data_iter = gluon.data.DataLoader(\n",
    "        gluon.data.vision.CIFAR10('./data', train=True, transform=transformer),\n",
    "        batch_size=batch_size, shuffle=True, last_batch='discard')\n",
    "    for i, batch in enumerate(data_iter):\n",
    "        if max_batches != -1 and i >= max_batches:\n",
    "            print(\"Reached {} batches. Saving model.\".format(max_batches))\n",
    "            break\n",
    "        d, l = batch\n",
    "        data = d.as_in_context(ctx).astype(dtype, copy=False)\n",
    "        label = l.as_in_context(ctx)\n",
    "        with autograd.record():\n",
    "            output = net(data)\n",
    "            loss = softmax_cross_entropy(output, label)\n",
    "        loss.backward()\n",
    "        trainer.step(data.shape[0])\n",
    "        \n",
    "    net.export(name)\n",
    "    return net\n",
    "\n",
    "def get_model(name, ctx):\n",
    "    return mx.gluon.block.SymbolBlock.imports(name+'-symbol.json', ['data'], name+'-0000.params', ctx=ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With normal Gluon block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached 300 batches. Saving model.\n",
      "48.82793569564819\n"
     ]
    }
   ],
   "source": [
    "def fp32_transformer(data, label):\n",
    "    data = mx.image.imresize(data, 224, 224)\n",
    "    data = mx.nd.transpose(data, (2,0,1))\n",
    "    data = data.astype(np.float32, copy=False)\n",
    "    return data, label\n",
    "\n",
    "train_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.CIFAR10('./data', train=True, transform=fp32_transformer),\n",
    "    batch_size=32, shuffle=True, last_batch='discard')\n",
    "net = train_model(np.float32, 'fp32')\n",
    "# net = get_model('fp32')\n",
    "\n",
    "res_list = []\n",
    "import time\n",
    "start = time.time()\n",
    "for i, batch in enumerate(train_data):\n",
    "    if max_batches_infer != -1 and i >= max_batches_infer:\n",
    "        print(\"Reached {} batches.\".format(max_batches_infer))\n",
    "        break\n",
    "    d, l = batch\n",
    "    data = d.as_in_context(ctx)\n",
    "    res = net(data)\n",
    "    res_list.append((res, l))\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25358114596670933\n"
     ]
    }
   ],
   "source": [
    "print(acc(res_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With fp16 Gluon block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached 300 batches. Saving model.\n",
      "57.90255570411682\n"
     ]
    }
   ],
   "source": [
    "def fp16_transformer(data, label):\n",
    "    data = mx.image.imresize(data, 224, 224)\n",
    "    data = mx.nd.transpose(data, (2,0,1))\n",
    "    data = data.astype(np.float16, copy=False)\n",
    "    return data, label\n",
    "\n",
    "train_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.CIFAR10('./data', train=True, transform=fp16_transformer),\n",
    "    batch_size=32, shuffle=True, last_batch='discard')\n",
    "\n",
    "net = train_model(np.float16, 'fp16', multi_precision=True)\n",
    "# net = get_model('fp16')\n",
    "\n",
    "res_list = []\n",
    "import time\n",
    "start = time.time()\n",
    "for i, batch in enumerate(train_data):\n",
    "    if max_batches_infer != -1 and i >= max_batches_infer:\n",
    "        print(\"Reached {} batches.\".format(max_batches_infer))\n",
    "        break\n",
    "    d, l = batch\n",
    "    data = d.as_in_context(ctx)\n",
    "    res = net(data)\n",
    "    res_list.append((res, l))\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28026968629961585\n"
     ]
    }
   ],
   "source": [
    "print(acc(res_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float16'>\n",
      "<class 'numpy.float16'>\n",
      "<class 'numpy.float16'>\n",
      "<class 'numpy.float16'>\n",
      "<class 'numpy.float16'>\n",
      "<class 'numpy.float16'>\n",
      "<class 'numpy.float16'>\n",
      "<class 'numpy.float16'>\n",
      "<class 'numpy.float16'>\n",
      "<class 'numpy.float16'>\n",
      "<class 'numpy.float16'>\n",
      "<class 'numpy.float16'>\n",
      "<class 'numpy.float16'>\n",
      "<class 'numpy.float16'>\n",
      "<class 'numpy.float16'>\n",
      "<class 'numpy.float16'>\n"
     ]
    }
   ],
   "source": [
    "# Double checking that all params are indeed fp16.\n",
    "net.cast(np.float16)\n",
    "params = net.collect_params()\n",
    "for k in params:\n",
    "    print(params[k].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (User)",
   "language": "python",
   "name": "user_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
